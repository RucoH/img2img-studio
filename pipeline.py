# pipeline.py

"""
ğŸ‡¹ğŸ‡· Stable Diffusion img2img pipeline modÃ¼lÃ¼:
- Model yÃ¼kleme
- Img2img dÃ¶nÃ¼ÅŸÃ¼m fonksiyonu
ğŸ‡¬ğŸ‡§ Stable Diffusion img2img pipeline module:
- Model loading
- Img2img generation function
"""
import os
from diffusers import StableDiffusionImg2ImgPipeline
import torch
from PIL import Image

# ğŸ‡¹ğŸ‡· Hugging Face eriÅŸimi iÃ§in token (gerekirse)
# ğŸ‡¬ğŸ‡§ HF access token for private models (if needed)
HF_TOKEN = os.getenv("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")

# ğŸ‡¹ğŸ‡· Modeli yÃ¼kleyen fonksiyon
# ğŸ‡¬ğŸ‡§ Function to load the Stable Diffusion img2img model
def load_model(
    model_id: str = "kandinsky-community/kandinsky-2-2-decoder"
) -> StableDiffusionImg2ImgPipeline:
    """
    ğŸ‡¹ğŸ‡· VarsayÄ±lan model "gsdf/Counterfeit-V2.5" olarak ayarlandÄ±: yÃ¼ksek detay, herkese aÃ§Ä±k.
    ğŸ‡¬ğŸ‡§ Default model set to "gsdf/Counterfeit-V2.5": high-detail, public.

    Arg:
        model_id (str): ğŸ‡¹ğŸ‡· HF model identifier / ğŸ‡¬ğŸ‡§ HuggingFace model name

    Returns:
        StableDiffusionImg2ImgPipeline: ğŸ‡¹ğŸ‡· YÃ¼klenmiÅŸ pipeline / ğŸ‡¬ğŸ‡§ Loaded pipeline
    """
    # ğŸ‡¹ğŸ‡· Kimlik doÄŸrulama tokenâ€™Ä± ekle (private modelse)
    # ğŸ‡¬ğŸ‡§ Include auth token if the model is private
    kwargs = {}
    if HF_TOKEN:
        kwargs["use_auth_token"] = HF_TOKEN

    # ğŸ‡¹ğŸ‡· Pipelineâ€™i oluÅŸtur ve cihaza taÅŸÄ±
    # ğŸ‡¬ğŸ‡§ Create the pipeline and move to device
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        **kwargs
    )
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return pipe.to(device)

# ğŸ‡¹ğŸ‡· GÃ¶rselden gÃ¶rsel Ã¼reten fonksiyon
# ğŸ‡¬ğŸ‡§ Image-to-image generation function
def img2img_generate(
    pipeline: StableDiffusionImg2ImgPipeline,
    input_image: Image.Image,
    prompt: str,
    strength: float = 0.75,
    guidance_scale: float = 7.5
) -> Image.Image:
    """
    ğŸ‡¹ğŸ‡· Girdi gÃ¶rselini ve promptâ€™u kullanarak dÃ¶nÃ¼ÅŸÃ¼m yapar.
    ğŸ‡¬ğŸ‡§ Transforms the input image using the prompt.

    Args:
        pipeline: ğŸ‡¹ğŸ‡· YÃ¼klenmiÅŸ pipeline / ğŸ‡¬ğŸ‡§ Loaded pipeline
        input_image: ğŸ‡¹ğŸ‡· BaÅŸlangÄ±Ã§ gÃ¶rseli / ğŸ‡¬ğŸ‡§ Input image
        prompt: ğŸ‡¹ğŸ‡· Metin komutu / ğŸ‡¬ğŸ‡§ Text prompt
        strength: ğŸ‡¹ğŸ‡· DÃ¶nÃ¼ÅŸÃ¼m gÃ¼cÃ¼ (0.0â€“1.0) / ğŸ‡¬ğŸ‡§ Transformation strength
        guidance_scale: ğŸ‡¹ğŸ‡· Prompt sadakati (1.0â€“15.0) / ğŸ‡¬ğŸ‡§ Prompt adherence

    Returns:
        Image.Image: ğŸ‡¹ğŸ‡· Ãœretilen gÃ¶rsel / ğŸ‡¬ğŸ‡§ Generated image
    """
    # ğŸ‡¹ğŸ‡· GÃ¶rseli RGBâ€™ye Ã§evir ve yeniden boyutlandÄ±r
    # ğŸ‡¬ğŸ‡§ Convert to RGB and resize
    image = input_image.convert("RGB").resize((512, 512))

    # ğŸ‡¹ğŸ‡· Pipelineâ€™i Ã§alÄ±ÅŸtÄ±r
    # ğŸ‡¬ğŸ‡§ Run the pipeline
    result = pipeline(
        prompt=prompt,
        image=image,
        strength=strength,
        guidance_scale=guidance_scale
    )
    return result.images[0]

# ğŸ‡¹ğŸ‡· Test bloÄŸu: Bu dosya doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda
# ğŸ‡¬ğŸ‡§ Test block: Run this file directly to check model loading
if __name__ == "__main__":
    print("â³ Model yÃ¼kleniyor / Loading model...")
    pipe = load_model()
    print("âœ… Model baÅŸarÄ±yla yÃ¼klendi! / Model loaded successfully!")
