# pipeline.py

"""
ğŸ‡¹ğŸ‡· Kandinsky 2.2 img2img modÃ¼lÃ¼:
- Prior pipeline ile gÃ¶rÃ¼ntÃ¼ embedâ€™i oluÅŸturma
- Decoder pipeline ile img2img oluÅŸturma
ğŸ‡¬ğŸ‡§ Kandinsky 2.2 img2img module:
- Generates image embeddings using the Prior pipeline
- Generates images using the Decoder pipeline
"""
import os
import torch
from diffusers import KandinskyV22PriorPipeline, KandinskyV22Img2ImgPipeline
from PIL import Image

# ğŸ‡¹ğŸ‡· Gated modellere eriÅŸim iÃ§in token ( gerekiyorsa )
# ğŸ‡¬ğŸ‡§ HF token for accessing gated models (if needed)
HF_TOKEN = os.getenv("HF_TOKEN")

# ğŸ‡¹ğŸ‡· TÃ¼m pipelineâ€™larÄ± yÃ¼kler: prior ve decoder
# ğŸ‡¬ğŸ‡§ Load both Prior and Decoder pipelines
def load_pipelines(
    prior_id: str = "kandinsky-community/kandinsky-2-2-prior",
    decoder_id: str = "kandinsky-community/kandinsky-2-2-decoder"
) -> tuple[KandinskyV22PriorPipeline, KandinskyV22Img2ImgPipeline]:
    """
    ğŸ‡¹ğŸ‡· Prior ve Decoder pipelineâ€™larÄ±nÄ± indirir ve cihaza taÅŸÄ±r.
    ğŸ‡¬ğŸ‡§ Downloads Prior and Decoder pipelines and moves them to device.
    """
    kwargs = {}
    if HF_TOKEN:
        kwargs["use_auth_token"] = HF_TOKEN

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # ğŸ‡¹ğŸ‡· Prior pipeline: prompt + image -> image_embeds, negative_image_embeds
    # ğŸ‡¬ğŸ‡§ Prior pipeline: prompt + image -> image_embeds, negative_image_embeds
    prior = KandinskyV22PriorPipeline.from_pretrained(
        prior_id,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        **kwargs
    )
    prior = prior.to(device)

    # ğŸ‡¹ğŸ‡· Decoder pipeline: image_embeds -> final image
    # ğŸ‡¬ğŸ‡§ Decoder pipeline: image_embeds -> final image
    decoder = KandinskyV22Img2ImgPipeline.from_pretrained(
        decoder_id,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        **kwargs
    )
    decoder = decoder.to(device)

    return prior, decoder

# ğŸ‡¹ğŸ‡· img2img oluÅŸtur: Ã¶ncelikle embed Ã¼ret, sonra decode et
# ğŸ‡¬ğŸ‡§ Image-to-image: first embed, then decode
def img2img_generate(
    prior_pipe: KandinskyV22PriorPipeline,
    decoder_pipe: KandinskyV22Img2ImgPipeline,
    input_image: Image.Image,
    prompt: str,
    strength: float = 0.5,
    num_inference_steps: int = 25,
    guidance_scale: float = 7.5
) -> Image.Image:
    """
    ğŸ‡¹ğŸ‡· Girdi gÃ¶rseli ve prompt ile dÃ¶nÃ¼ÅŸÃ¼m yapar.
    ğŸ‡¬ğŸ‡§ Transforms the input image using the prompt.

    Args:
        prior_pipe: ğŸ‡¹ğŸ‡· Prior pipeline
        decoder_pipe: ğŸ‡¹ğŸ‡· Decoder pipeline
        input_image (Image.Image): ğŸ‡¹ğŸ‡· BaÅŸlangÄ±Ã§ gÃ¶rseli / ğŸ‡¬ğŸ‡§ Input image
        prompt (str): ğŸ‡¹ğŸ‡· Metin komutu / ğŸ‡¬ğŸ‡§ Text prompt
        strength (float): ğŸ‡¹ğŸ‡· Ã–n embed dÃ¶nÃ¼ÅŸÃ¼m gÃ¼cÃ¼ (0.0â€“1.0) / ğŸ‡¬ğŸ‡§ Embedding strength
        num_inference_steps (int): ğŸ‡¹ğŸ‡· Decoder adÄ±m sayÄ±sÄ± / ğŸ‡¬ğŸ‡§ Decoder inference steps
        guidance_scale (float): ğŸ‡¹ğŸ‡· Prompt sadakati (1.0â€“15.0) / ğŸ‡¬ğŸ‡§ Guidance scale

    Returns:
        Image.Image: ğŸ‡¹ğŸ‡· Ãœretilen gÃ¶rsel / ğŸ‡¬ğŸ‡§ Generated image
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # ğŸ‡¹ğŸ‡· Prior pipeline embed Ã¼retimi
    # ğŸ‡¬ğŸ‡§ Generate image embeddings
    prior_output = prior_pipe(
        prompt=prompt,
        image=input_image,
        strength=strength
    )
    image_embeds = prior_output.image_embeds
    negative_embeds = prior_output.negative_image_embeds

    # ğŸ‡¹ğŸ‡· Decoder pipeline ile gÃ¶rsel oluÅŸturma
    # ğŸ‡¬ğŸ‡§ Generate final image via decoder pipeline
    result = decoder_pipe(
        image_embeds=image_embeds,
        negative_image_embeds=negative_embeds,
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale
    )

    return result.images[0]

# ğŸ‡¹ğŸ‡· Test bloÄŸu: Bu dosya doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda
# ğŸ‡¬ğŸ‡§ Test block when run directly
if __name__ == "__main__":
    print("â³ Loading Kandinsky 2.2 pipelines...")
    prior, decoder = load_pipelines()
    print("âœ… Prior and Decoder loaded successfully!")
